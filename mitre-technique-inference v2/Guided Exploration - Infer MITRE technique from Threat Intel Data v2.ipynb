{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Exploration - Infer MITRE technique from Threat Intel Data v2\n",
    "\n",
    "__Notebook Version:__ 1.0 <br>\n",
    "__Notebook Author:__ Vani Asawa<br>\n",
    "\n",
    "\n",
    "__Python Version:__ >=Python 3.8<br>\n",
    "__Platforms Supported:__  Azure Machine Learning Notebooks<br>\n",
    "\n",
    "__Data Source Required:__ None<br>\n",
    "\n",
    "__GPU Compute Required:__ No<br>\n",
    "__GPU Compute Recommended:__ Yes<br>\n",
    "\n",
    "__Requirements Path:__ ```../mitre-technique-inference/requirements.txt```<br>\n",
    "__Essential Packages:__ \n",
    "- ipywidgets==7.5.1\n",
    "- transformers==4.5.1\n",
    "- torch==1.10.2\n",
    "- msticpy==2.1.2\n",
    "- nltk==3.6.2\n",
    "- iocextract==1.13.1\n",
    "- shap==0.41.0\n",
    "\n",
    "## Motivation\n",
    "**Cyber Threat Intelligence** (CTI) provides a framework for threat analysts to document the operations of a threat actor group, and record the findings of their investigations of specific cyber attack incidents.\n",
    "\n",
    "With the increasing number and sophistication of attacks occuring across organization's workspace, CTI allows organisations to:\n",
    "- Develop a more robust and proactive security posture \n",
    "- Better detect threat vulnerabilities in their infrastructre \n",
    "- Adopt security solutions and policies that allow them to better protect their environment. \n",
    "\n",
    "For example **Indicators of Compromise (IoC)** represent network artifacts of a cyber intrusion and are widely used in intrusion detection systems and antivirus softwares to detect future attacks.\n",
    "\n",
    "**Threat Intel Data** is another form of CTI which comprises of unstructured text data, describing the tools, techniques and procedures (TTPs) used by threat actor groups in a cyber operation. Historically TI data is made available to the security community in the form of *blog posts reports* and *white papers*. With the increasing numebr of cyber attacks, it is not scalable to manually process this growing corpus of TI data to understand the motivations capabilities and TTPs associated with an actor group. Additionally TI data does not facilitate easy extraction of IoCs which, if documented in the report, can result in the loss of known indicators in the threat intelligence corpus. This opens up several avenues for **Machine Learning**, more particularly **Natural Language Processing** (NLP), to identify TTPs and extract IoCs from this data.\n",
    "\n",
    "The **MITRE ATT&CK** framework is an openly-sourced knowledge base of TTPs used by adversaries across enterprise and mobile applications. MITRE TTPs allow people and organizations to proactively identify vulnerabilites in their system based on the behaviors, methods and patterns of activity used by an actor group in different stages of a cyber operation. More information about the kinds of tactics and techniques used by threat actors can be found [here](https://attack.mitre.org/techniques/enterprise/).\n",
    "\n",
    "#################################\n",
    "\n",
    "In this notebook we use NLP to\n",
    "1. *Detect MITRE TTPs* using the **Distil-GPT2** transformer model, &\n",
    "2. *Extract IoCs* using the ```iocextract``` package, and ```msticpy```'s IoC Extractor.\n",
    "\n",
    "from unstructured English text-based Threat Intel data. We also provide some explainability into the TTP predictions made by our NLP model by identifying specific words or phrases in the input TI data that contribute to the prediction, using [SHAP](https://arxiv.org/pdf/1705.07874.pdf) values.\n",
    "\n",
    "#################################\n",
    "\n",
    "## Prerequisites\n",
    "**Please do not run the notebook cells all at once**. The cells need to be run sequentially and successfully executed before proceeding with the remainder of the notebook.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "0. Installations [One-Time Setup]\n",
    "1. Imports\n",
    "2. Configure Input Data and Model Parameters\n",
    "3. Run\n",
    "4. Results\n",
    "\n",
    "Note - If you are copying this notebook, then you need to copy the associated utils folder.\n",
    "- Can we bundle the package and requirements text in a zip file? A whl?\n",
    "- Make a utils.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installations [One-Time Setup]\n",
    "\n",
    "Please configure a virtual environment, before downloading the packages in ```../mitre-technique-inference/requirements.txt``` in your virtual environment. Download the model artifacts.\n",
    "\n",
    "### Creating a virtual environment\n",
    "\n",
    "Navigate to the ```\\Azure-Sentinel-Notebooks``` folder in terminal, configure a virtual environment, and download the ```../mitre-technique-inference/requirements.txt``` packages in your venv -\n",
    "\n",
    "``` \n",
    "    > pip install virtualenv\n",
    "    > virtualenv <VENV_NAME>\n",
    "    > source <VENV_NAME>\\Scripts\\activate\n",
    "    > cd mitre-technique-inference\n",
    "    > pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Downloading Model Artifacts\n",
    "\n",
    "Estimated Time: < 10 minutes\n",
    "\n",
    "- [**Distil-GPT2**](https://huggingface.co/distilgpt2) is an English-language model, pre-trained with the smallest GPT-2 Model, and was developed using knowledge-distillation, to serve as a faster, light-weight version of GPT-2. \n",
    "\n",
    "- We train a Distil-GPT2 model on publicly available Threat Intel data that has been mapped to Enterprise Techniques by security experts. We have scraped data from TRAM, Sentinel Hunting and Detection Queries, Sigma, CTID, and MITRE Repositories to create our training dataset, comprising of 13k entries. The model has been trained on all 191 MITRE Enterprise techniques, but the number of entries per technique used for training varies.\n",
    "\n",
    "- In order to download the model artifacts, you will need ```bash``` configured in your notebook environment. The bash script will download the trained ```distilgpt2-512``` model artifacts from [MSTICPy's Data Repository](https://github.com/microsoft/msticpy-data/tree/mitre-inference/mitre-inference-models) to the local path ```../mitre-technique-inference/artifacts/distilgpt2-512/*```. <br>\n",
    "\n",
    "- **Alternatively**, you can use GitHub to download the model artifacts to the above local path. \n",
    "\n",
    "- The model artifacts stored locally will comprise of:<br>\n",
    "\n",
    "    - ```../mitre-technique-inference/artifacts/distilgpt2-512/model_state_dicts``` - Model weights associated with the trained Distil-GPT2 Model.\n",
    "    - ```../mitre-technique-inference/artifacts/distilgpt2-512/labels``` - Mapping of prediction labels to MITRE Enterprise Techniques.\n",
    "    - ```../mitre-technique-inference/artifacts/distilgpt2-512/tokenizer``` - Trained Distil-GPT2 tokenizer associated with the model. <br>\n",
    "<br>\n",
    "\n",
    "- If you have access to a GPU, we HIGHLY recommend using a GPU in the inference environment. The notebook will detect the device that is used to run the notebook, and configure the model to run on that device.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash ./model.sh distilgpt2-512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-start the kernel and run the Notebook from **1. Imports**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Imports\n",
    "\n",
    "The modules used to run this notebook can be found under ```mitre-technique-inference/utils/*```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import utils\n",
    "from utils import main, inference, configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Input Data and Model Parameters,\n",
    "\n",
    "**IMPORTANT** In order to view the widgets in your Notebook, consider downloading the following jupyter extension via Terminal - ```jupyter labextension install @jupyter-widgets/jupyterlab-manager``` <br><br>\n",
    "\n",
    "The notebook requires the following parameters from the user:\n",
    "1. ***Threat Intel Data***: Unstructured, English threat report that the user would like to process through the NLP model.\n",
    "\n",
    "- Sample Report:\n",
    "\n",
    "    ```    \n",
    "    The Black Basta ransomware group quickly gained notoriety after it laid claim to massive breaches earlier this year. On April 20, 2022, a user under the name “Black Basta” sought out corporate network access credentials on underground forums in exchange for a share of the profits from their ransomware attacks. Specifically, the user was in the market for credentials that could compromise organizations based in English-speaking countries, including Australia, Canada, New Zealand, the UK, and the US.\n",
    "\n",
    "    Two days later, the American Dental Association (ADA) suffered a cyberattack that led it to shutter multiple systems. Data allegedly stolen from the ADA was published on the Black Basta leak site only 96 hours after the attack.\n",
    "\n",
    "    While it was previously assumed that the ransomware group used bought or stolen corporate network access credentials to infiltrate its victims’ networks, our analysis of another set of samples monitored within a 72-hour time frame shows a possible correlation between the Qakbot trojan and the Black Basta ransomware. Black Basta continued to evolve, and in June, a Linux build of the ransomware that encrypts VMware ESXi virtual machines was discovered in the wild.\n",
    "\n",
    "    Interestingly, the ransomware group does not appear to distribute its malware at random. That Black Basta’s operators have turned to underground markets to acquire network access credentials and have hard-coded a unique ID in every Black Basta build betrays their mature understanding of how ransomware works as a business. While Black Basta may be a newly formed group, the individuals behind it are likely seasoned cybercriminals.\n",
    "    ```\n",
    "\n",
    "2. ***Minimum Score Threshold***: The TTP predictions for a sample TI input data have an associated confidence score from the NLP model, ranging from 0 (not very confident) to 1 (most confident). Filter the results to predictions with confidence >= threshold configured by the user. <br>\n",
    "\n",
    "- Default threshold: **0.6** <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_widgets = configs.configure_model_parameters()\n",
    "for k in config_widgets.keys():\n",
    "       display(config_widgets[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run\n",
    "\n",
    "Size of Threat Intel Report - Mention time estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, inference_df, iocs_df = main.go(\n",
    "    config_widgets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.print_detailed_report(\n",
    "    inference_df,\n",
    "    configs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary Statistics for Inference Dataframe: ')\n",
    "print('Shape of Inference Dataframe: ', inference_df.shape)\n",
    "if not inference_df.empty:\n",
    "    print('Sample rows: ')\n",
    "    display(inference_df.head(5))\n",
    "else:\n",
    "    print('No results obtained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary Statistics for IOCs Dataframe: ')\n",
    "print('Shape of IOCs Dataframe: ', iocs_df.shape)\n",
    "if not iocs_df.empty:\n",
    "    print('Distinct counts for each category of IOCs: ')\n",
    "    display(iocs_df.groupby('IOC_Type').count().rename(columns={'IOC_Value': 'Count'}))\n",
    "    print('Sample rows: ')\n",
    "    display(iocs_df.head(5))\n",
    "else:\n",
    "    print('No IOCs obtained.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77f383741783d7e0512e57117415d4f356f74ce6c9a106e190743629feb8d961"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
