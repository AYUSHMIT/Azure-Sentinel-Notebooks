{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Exploration - Infer MITRE technique from Threat Intel Data\n",
    "\n",
    "__Notebook Version:__ 1.0 <br>\n",
    "__Notebook Author:__ Vani Asawa<br>\n",
    "\n",
    "\n",
    "__Python Version:__ >=Python 3.8<br>\n",
    "__Platforms Supported:__  Azure Machine Learning Notebooks<br>\n",
    "\n",
    "__Data Source Required:__ None<br>\n",
    "\n",
    "__GPU Compute Required:__ No<br>\n",
    "__GPU Compute Recommended:__ Yes<br>\n",
    "\n",
    "__Requirements Path:__ ```../mitre-technique-inference/requirements.txt```<br>\n",
    "__Essential Packages:__ \n",
    "- ipywidgets==7.5.1\n",
    "- transformers==4.5.1\n",
    "- torch==1.10.2\n",
    "- msticpy==2.1.2\n",
    "- nltk==3.6.2\n",
    "- iocextract==1.13.1\n",
    "- shap==0.41.0\n",
    "\n",
    "## Description\n",
    "**Cyber Threat Intelligence** (CTI) provides a framework for threat analysts to document the operations of a threat actor group and record the findings of their investigations of specific cyber attack incidents.\n",
    "\n",
    "With the increasing number and sophistication of attacks occuring across organization's workspace CTI allows organisations to develop a more robust and proactive security posture better detect threat vulnerabilities in their infrastructre and adopt security solutions and policies that allow them to better protect their environment. For example **Indicators of Compromise (IoC)** represent network artifacts of a cyber intrusion and are widely used in intrusion detection systems and antivirus softwares to detect future attacks.\n",
    "\n",
    "**Threat Intel Data** is another form of CTI which comprises of rich unstructured textual data describing the tools techniques and procedures used by threat actor groups in a cyber operation. Historically TI data is made available to the security community in the form of blog posts reports and white papers. With the increasing numebr of cyber attacks it is not scalable to manually process this growing corpus of TI data to understand the motivations capabilities and TTPs associated with an actor group. Additionally TI data does not facilitate easy extraction of IoCs which if documented in the report can result in the loss of known indicators in the threat intelligence corpus. This opens up several avenues for **Machine Learning** more particularly **Natural Language Processing** (NLP) to identify TTPs and IoCs from this data.\n",
    "\n",
    "The **MITRE ATT&CK** framework is an openly-sourced knowledge base of TTPs used by adversaries across enterprise and mobile applications. MITRE TTPs allow people and organizations to proactively identify vulnerabilites in their system based on the behaviors methods and patterns of activity used by an actor group in different stages of a cyber operation.\n",
    "\n",
    "#################################\n",
    "\n",
    "In this notebook we use NLP to\n",
    "1. *Detect MITRE TTPs* &\n",
    "2. *Extract IoCs*\n",
    "\n",
    "from unstructured English text-based Threat Intel data. We also provide some explainability into the TTP predictions made by our NLP model by identifying specific words or phrases in the input TI data that contribute to the prediction.\n",
    "\n",
    "#################################\n",
    "\n",
    "## Prerequisites\n",
    "**Please do not run the notebook cells all at once**. The cells need to be run sequentially and successfully executed before proceeding with the remainder of the notebook.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Imports\n",
    "2. Configure Input Data and Model Parameters\n",
    "3. Get Model Artifacts\n",
    "4. Process TI Data\n",
    "5. Inference\n",
    "6. Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n",
    "\n",
    "Please download the packages in ```../mitre-technique-inference/requirements.txt``` in your virtual environment before running the rest of the cells in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "############### REQUIREMENTS.TXT ################\n",
    "# requirements_path = os.path.join(os.getcwd(), 'requirements.txt')\n",
    "# os.system(f'pip install -r {requirements_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports\n",
    "\n",
    "The modules used to run this notebook can be found under ```mitre-technique-inference/utils/*```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "from utils import (\n",
    "    configs as config_utils,\n",
    "    storage as storage_utils,\n",
    "    inference as inference_utils,\n",
    "    process as process_utils,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Input Data and Model Parameters,\n",
    "The notebook requires the following parameters from the user:\n",
    "1. ***Threat Intel Data***: Unstructured, English text data that the user would like to process through the NLP model. If you are inputting multiple text reports in the widget, please input the reports separated by an empty line. Do not include any commas, punctuations, or brackets before and after the reports. <br>\n",
    "- For example: Here, we are processing three different threat reports, which are separated by an empty line. The length of each report can be more than one sentence. In this example, for the purposes of succinct documentation, the length of each report is 1 sentence.\n",
    "\n",
    "    ```\n",
    "    Like many threat groups, TG-3390 conducts strategic web compromises (SWCs), also known as watering hole attacks, on websites associated with the target organization's vertical or demographic to increase the likelihood of finding victims with relevant information.\n",
    "\n",
    "    Threat groups use strategic web compromises (SWCs), also known as watering hole attacks, to target a wide array of potential victims.\n",
    "\n",
    "    A build tool is likely being used by these attackers that allows the operator to configure details such as C2 addresses, C2 encryption keys, and a campaign code.\n",
    "    ```\n",
    "       \n",
    "2. ***Select NLP Model***: We have trained four variations of GPT-2 transformer models using publicly-available threat intel datasets that map TI data to MITRE TTPs. \n",
    "- *distilgpt2* models are 40% lower in storage size than the *gpt2* models <br>\n",
    "\n",
    "- *distilgpt2-1024* and *gpt2-1024* models process more word tokens in a single threat input statement than the *distilgpt2-512* and *distilgpt2-1024* models, which can be particularly useful if your threat intel data is long. <br>\n",
    "\n",
    "- Default model: **distilgpt2_512** <br><br>\n",
    "\n",
    "3. ***Minimum Score Threshold***: The TTP predictions for a sample TI input data have an associated confidence score from the NLP model, ranging from 0 (less confident) to 1 (most confident). Filter the results to predictions with confidence >= threshold configured by the user. <br>\n",
    "\n",
    "- Default threshold: **0.7** <br> <br>\n",
    "       \n",
    "4. ***Chunk Threat Intel Data?***: \n",
    "- One of the limitations of the transformer models is that they can only process inputs upto a certain length, after which the rest of the report is discarded. \n",
    "- As a result, the model will lose out on potentially important information about the actor's TTPs, described in the latter parts of the report. \n",
    "- If a single threat report in your input is longer than 3 sentences, we recommend **chunking** - The model will process the sentences in your input data in batches of 3 sentences, hence assigning a TTP prediction for each chunk of data, and processing the entire report. <br>\n",
    "\n",
    "- Default value: **Yes** <br><br>\n",
    "\n",
    "5. ***Extract Indicators of Compromise (IoCs)***: Extract IoCs from the input TI data. <br>\n",
    "\n",
    "- Default value: **Yes** <br><br>\n",
    "\n",
    "6. ***Get NLP Model Explainability***: Obtain further insights into which words and phrases in your input data contributed to the TTP prediction. <br>\n",
    "\n",
    "- Default value: **Yes** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50744d999c024afb83756604d8802499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Threat Intel Data:', layout=Layout(height='200px', width='80%'), style=Descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2b5d7dd5c24c30bc7c8f9d6c4bd01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Select NLP Model: ', layout=Layout(height='80px', width='50%'), options=('distilgpt2-512',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f389b52a9634e1cad25851098a40a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.7, description='Minimum Score Threshold: ', layout=Layout(height='30px', width='50%'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8372a529e2da4bd58b6fe0c49638c146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Chunk Threat Intel data?: ', layout=Layout(height='80px', width='50%'), options=('Yes', 'N…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5846de7f10cc4406a3876e17b8a260be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Extract Indicators Of Compromise (IoCs)?: ', layout=Layout(height='80px', width='50%'), op…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fbdc18fb2844f9bbe5d25720ff732e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Get NLP Model Explainability?: ', layout=Layout(height='80px', width='50%'), options=('Yes…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_config_widgets = config_utils.configure_model_parameters()\n",
    "for k in all_config_widgets.keys():\n",
    "       display(all_config_widgets[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### SUMMARY #################### \n",
      "\n",
      "Threat Intel (TI) Data: [\n",
      "\n",
      "\t\"Like many threat groups, TG-3390 conducts strategic web compromises (SWCs), also known as watering hole attacks, on websites associated with the target organization's vertical or demographic to increase the likelihood of finding victims with relevant information.\", \n",
      "\n",
      "\t\"Threat groups use strategic web compromises (SWCs), also known as watering hole attacks, to target a wide array of potential victims.\", \n",
      "\n",
      "\t\"A build tool is likely being used by these attackers that allows the operator to configure details such as C2 addresses, C2 encryption keys, and a campaign code.\"\n",
      "\n",
      "]\n",
      "\n",
      "# of TI entries: 3\n",
      "\n",
      "NLP Model: distilgpt2-512\n",
      "\n",
      "Minimum Score Threshold: 0.1\n",
      "\n",
      "Chunk Threat Intel data?: No\n",
      "\n",
      "Extract Indicators Of Compromise (IoCs)?: Yes\n",
      "\n",
      "Get NLP Model Explainability?: Yes\n",
      "\n",
      "################################################# \n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_configs = {\n",
    "    k: v.value for k, v in all_config_widgets.items()\n",
    "}\n",
    "\n",
    "configs = config_utils.format_user_configuration(set_configs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model Artifacts\n",
    "\n",
    "- In order to download the model artifacts, you will need ```bash``` configured in your notebook environment.\n",
    "- The bash script will download the model configured by the user from [MSTICPy's Data Repository](https://github.com/microsoft/msticpy-data/tree/mitre-inference/mitre-inference-models) to your local machine. \n",
    "- You do not need to re-run the bash script once the model has been downloaded to your machine, if you choose to re-run the notebook with the same model configuration (unless you have removed the model folder).\n",
    "- All the model artifacts associated with the configured model will be stored under ```mitre-technique-inference/artifacts/CONFIGURED-MODEL-NAME/*```. \n",
    "- If you have access to a GPU, we HIGHLY recommend using a GPU in the inference environment. The notebook will detect the device that is used to run the notebook, and configure the model to run on that device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading labels for model distilgpt2-512..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘distilgpt2-512’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "100 19532  100 19532    0     0  20845      0 --:--:-- --:--:-- --:--:-- 20845\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      " 67 1042k   67  706k    0     0   534k      0  0:00:01  0:00:01 --:--:--  534k\n",
      "100 1042k  100 1042k    0     0   727k      0  0:00:01  0:00:01 --:--:-- 3082k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloaded labels for model distilgpt2-512.\n",
      "Downloading tokenizer for model distilgpt2-512...\n",
      "Downloaded tokenizer for model distilgpt2-512.\n",
      "Downloading model dicts for model distilgpt2-512...\n",
      "Downloaded model dicts for model distilgpt2-512.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0  319M    0  192k    0     0   218k      0  0:24:52 --:--:--  0:24:52  218k\n",
      "  1  319M    1 3471k    0     0  1843k      0  0:02:57  0:00:01  0:02:56 3263k\n",
      "  2  319M    2 6879k    0     0  2390k      0  0:02:16  0:00:02  0:02:14 3342k\n",
      "  3  319M    3 9967k    0     0  2570k      0  0:02:07  0:00:03  0:02:04 3257k\n",
      "  3  319M    3 12.2M    0     0  2573k      0  0:02:06  0:00:04  0:02:02 3089k\n",
      "  4  319M    4 15.5M    0     0  2697k      0  0:02:01  0:00:05  0:01:56 3132k\n",
      "  5  319M    5 18.5M    0     0  2754k      0  0:01:58  0:00:06  0:01:52 3096k\n",
      "  6  319M    6 21.4M    0     0  2761k      0  0:01:58  0:00:07  0:01:51 2972k\n",
      "  7  319M    7 22.6M    0     0  2611k      0  0:02:05  0:00:08  0:01:57 2644k\n",
      "  7  319M    7 23.2M    0     0  2413k      0  0:02:15  0:00:09  0:02:06 2256k\n",
      "  7  319M    7 25.1M    0     0  2369k      0  0:02:17  0:00:10  0:02:07 1981k\n",
      "  8  319M    8 28.0M    0     0  2422k      0  0:02:14  0:00:11  0:02:03 1964k\n",
      "  9  319M    9 30.8M    0     0  2382k      0  0:02:17  0:00:13  0:02:04 1814k\n",
      " 10  319M   10 34.2M    0     0  2524k      0  0:02:09  0:00:13  0:01:56 2367k\n",
      " 11  319M   11 37.4M    0     0  2575k      0  0:02:06  0:00:14  0:01:52 2897k\n",
      " 12  319M   12 40.6M    0     0  2619k      0  0:02:04  0:00:15  0:01:49 3164k\n",
      " 13  319M   13 43.6M    0     0  2646k      0  0:02:03  0:00:16  0:01:47 3178k\n",
      " 14  319M   14 46.4M    0     0  2662k      0  0:02:02  0:00:17  0:01:45 3459k\n",
      " 15  319M   15 49.0M    0     0  2659k      0  0:02:02  0:00:18  0:01:44 3034k\n",
      " 16  319M   16 51.7M    0     0  2663k      0  0:02:02  0:00:19  0:01:43 2923k\n",
      " 17  319M   17 54.6M    0     0  2678k      0  0:02:02  0:00:20  0:01:42 2862k\n",
      " 17  319M   17 57.3M    0     0  2684k      0  0:02:01  0:00:21  0:01:40 2815k\n",
      " 18  319M   18 59.9M    0     0  2682k      0  0:02:01  0:00:22  0:01:39 2754k\n",
      " 19  319M   19 62.7M    0     0  2689k      0  0:02:01  0:00:23  0:01:38 2805k\n",
      " 20  319M   20 64.6M    0     0  2660k      0  0:02:02  0:00:24  0:01:38 2650k\n",
      " 21  319M   21 67.5M    0     0  2669k      0  0:02:02  0:00:25  0:01:37 2635k\n",
      " 21  319M   21 70.0M    0     0  2669k      0  0:02:02  0:00:26  0:01:36 2602k\n",
      " 22  319M   22 72.2M    0     0  2619k      0  0:02:04  0:00:28  0:01:36 2351k\n",
      " 23  319M   23 75.3M    0     0  2671k      0  0:02:02  0:00:28  0:01:34 2584k\n",
      " 24  319M   24 79.1M    0     0  2713k      0  0:02:00  0:00:29  0:01:31 2976k\n",
      " 25  319M   25 82.8M    0     0  2748k      0  0:01:58  0:00:30  0:01:28 3156k\n",
      " 26  319M   26 84.3M    0     0  2698k      0  0:02:01  0:00:32  0:01:29 2850k\n",
      " 27  319M   27 87.5M    0     0  2726k      0  0:01:59  0:00:32  0:01:27 3376k\n",
      " 28  319M   28 90.3M    0     0  2729k      0  0:01:59  0:00:33  0:01:26 3065k\n",
      " 29  319M   29 93.1M    0     0  2734k      0  0:01:59  0:00:34  0:01:25 2861k\n",
      " 30  319M   30 95.8M    0     0  2735k      0  0:01:59  0:00:35  0:01:24 2655k\n",
      " 31  319M   31 99.0M    0     0  2748k      0  0:01:58  0:00:36  0:01:22 3077k\n",
      " 31  319M   31  101M    0     0  2736k      0  0:01:59  0:00:37  0:01:22 2805k\n",
      " 32  319M   32  103M    0     0  2733k      0  0:01:59  0:00:38  0:01:21 2758k\n",
      " 33  319M   33  106M    0     0  2733k      0  0:01:59  0:00:39  0:01:20 2727k\n",
      " 34  319M   34  108M    0     0  2728k      0  0:01:59  0:00:40  0:01:19 2681k\n",
      " 34  319M   34  111M    0     0  2718k      0  0:02:00  0:00:41  0:01:19 2494k\n",
      " 35  319M   35  114M    0     0  2725k      0  0:01:59  0:00:42  0:01:17 2636k\n",
      " 36  319M   36  116M    0     0  2725k      0  0:01:59  0:00:43  0:01:16 2661k\n",
      " 37  319M   37  119M    0     0  2718k      0  0:02:00  0:00:44  0:01:16 2599k\n",
      " 38  319M   38  121M    0     0  2719k      0  0:02:00  0:00:45  0:01:15 2643k\n",
      " 39  319M   39  124M    0     0  2726k      0  0:01:59  0:00:46  0:01:13 2790k\n",
      " 40  319M   40  127M    0     0  2732k      0  0:01:59  0:00:47  0:01:12 2800k\n",
      " 40  319M   40  130M    0     0  2727k      0  0:01:59  0:00:48  0:01:11 2745k\n",
      " 41  319M   41  133M    0     0  2733k      0  0:01:59  0:00:49  0:01:10 2860k\n",
      " 42  319M   42  135M    0     0  2730k      0  0:01:59  0:00:50  0:01:09 2834k\n",
      " 43  319M   43  138M    0     0  2739k      0  0:01:59  0:00:51  0:01:08 2863k\n",
      " 44  319M   44  141M    0     0  2748k      0  0:01:58  0:00:52  0:01:06 2892k\n",
      " 45  319M   45  145M    0     0  2758k      0  0:01:58  0:00:53  0:01:05 3063k\n",
      " 46  319M   46  148M    0     0  2768k      0  0:01:58  0:00:54  0:01:04 3125k\n",
      " 47  319M   47  151M    0     0  2778k      0  0:01:57  0:00:55  0:01:02 3267k\n",
      " 48  319M   48  155M    0     0  2791k      0  0:01:57  0:00:56  0:01:01 3330k\n",
      " 49  319M   49  158M    0     0  2807k      0  0:01:56  0:00:57  0:00:59 3436k\n",
      " 50  319M   50  161M    0     0  2813k      0  0:01:56  0:00:58  0:00:58 3409k\n",
      " 51  319M   51  165M    0     0  2826k      0  0:01:55  0:00:59  0:00:56 3456k\n",
      " 52  319M   52  168M    0     0  2837k      0  0:01:55  0:01:00  0:00:55 3495k\n",
      " 53  319M   53  172M    0     0  2848k      0  0:01:54  0:01:01  0:00:53 3505k\n",
      " 54  319M   54  175M    0     0  2854k      0  0:01:54  0:01:02  0:00:52 3405k\n",
      " 56  319M   56  179M    0     0  2875k      0  0:01:53  0:01:03  0:00:50 3600k\n",
      " 57  319M   57  182M    0     0  2878k      0  0:01:53  0:01:04  0:00:49 3507k\n",
      " 58  319M   58  185M    0     0  2887k      0  0:01:53  0:01:05  0:00:48 3497k\n",
      " 59  319M   59  188M    0     0  2891k      0  0:01:53  0:01:06  0:00:47 3418k\n",
      " 60  319M   60  191M    0     0  2890k      0  0:01:53  0:01:07  0:00:46 3332k\n",
      " 60  319M   60  193M    0     0  2880k      0  0:01:53  0:01:08  0:00:45 2940k\n",
      " 61  319M   61  196M    0     0  2878k      0  0:01:53  0:01:09  0:00:44 2869k\n",
      " 62  319M   62  198M    0     0  2864k      0  0:01:54  0:01:11  0:00:43 2563k\n",
      " 63  319M   63  202M    0     0  2875k      0  0:01:53  0:01:11  0:00:42 2660k\n",
      " 63  319M   63  203M    0     0  2865k      0  0:01:54  0:01:12  0:00:42 2528k\n",
      " 64  319M   64  206M    0     0  2865k      0  0:01:54  0:01:13  0:00:41 2658k\n",
      " 65  319M   65  209M    0     0  2867k      0  0:01:53  0:01:14  0:00:39 2713k\n",
      " 67  319M   67  214M    0     0  2894k      0  0:01:52  0:01:15  0:00:37 3333k\n",
      " 68  319M   68  218M    0     0  2903k      0  0:01:52  0:01:16  0:00:36 3321k\n",
      " 69  319M   69  221M    0     0  2909k      0  0:01:52  0:01:17  0:00:35 3552k\n",
      " 70  319M   70  224M    0     0  2912k      0  0:01:52  0:01:18  0:00:34 3607k\n",
      " 71  319M   71  226M    0     0  2909k      0  0:01:52  0:01:19  0:00:33 3548k\n",
      " 72  319M   72  230M    0     0  2916k      0  0:01:52  0:01:20  0:00:32 3253k\n",
      " 73  319M   73  233M    0     0  2920k      0  0:01:51  0:01:21  0:00:30 3171k\n",
      " 74  319M   74  236M    0     0  2926k      0  0:01:51  0:01:22  0:00:29 3195k\n",
      " 75  319M   75  240M    0     0  2934k      0  0:01:51  0:01:23  0:00:28 3289k\n",
      " 76  319M   76  244M    0     0  2954k      0  0:01:50  0:01:24  0:00:26 3671k\n",
      " 77  319M   77  248M    0     0  2958k      0  0:01:50  0:01:25  0:00:25 3637k\n",
      " 78  319M   78  251M    0     0  2964k      0  0:01:50  0:01:26  0:00:24 3680k\n",
      " 79  319M   79  254M    0     0  2964k      0  0:01:50  0:01:27  0:00:23 3598k\n",
      " 80  319M   80  257M    0     0  2967k      0  0:01:50  0:01:28  0:00:22 3520k\n",
      " 81  319M   81  260M    0     0  2968k      0  0:01:50  0:01:29  0:00:21 3210k\n",
      " 82  319M   82  263M    0     0  2972k      0  0:01:49  0:01:30  0:00:19 3223k\n",
      " 83  319M   83  266M    0     0  2973k      0  0:01:49  0:01:31  0:00:18 3144k\n",
      " 84  319M   84  270M    0     0  2982k      0  0:01:49  0:01:32  0:00:17 3299k\n",
      " 85  319M   85  273M    0     0  2987k      0  0:01:49  0:01:33  0:00:16 3340k\n",
      " 86  319M   86  276M    0     0  2985k      0  0:01:49  0:01:34  0:00:15 3289k\n",
      " 87  319M   87  279M    0     0  2986k      0  0:01:49  0:01:35  0:00:14 3228k\n",
      " 88  319M   88  282M    0     0  2991k      0  0:01:49  0:01:36  0:00:13 3313k\n",
      " 89  319M   89  286M    0     0  2996k      0  0:01:49  0:01:37  0:00:12 3247k\n",
      " 90  319M   90  288M    0     0  2992k      0  0:01:49  0:01:38  0:00:11 3089k\n",
      " 91  319M   91  291M    0     0  2991k      0  0:01:49  0:01:39  0:00:10 3101k\n",
      " 92  319M   92  294M    0     0  2988k      0  0:01:49  0:01:40  0:00:09 3023k\n",
      " 92  319M   92  295M    0     0  2974k      0  0:01:49  0:01:41  0:00:08 2648k\n",
      " 93  319M   93  297M    0     0  2964k      0  0:01:50  0:01:42  0:00:08 2321k\n",
      " 94  319M   94  300M    0     0  2960k      0  0:01:50  0:01:43  0:00:07 2320k\n",
      " 94  319M   94  303M    0     0  2959k      0  0:01:50  0:01:44  0:00:06 2317k\n",
      " 95  319M   95  303M    0     0  2931k      0  0:01:51  0:01:46  0:00:05 1825k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95  319M   95  303M    0     0  2904k      0  0:01:52  0:01:47  0:00:05 1512k\n",
      " 95  319M   95  303M    0     0  2877k      0  0:01:53  0:01:48  0:00:05 1139k\n",
      " 95  319M   95  303M    0     0  2850k      0  0:01:54  0:01:49  0:00:05  639k\n",
      " 95  319M   95  303M    0     0  2824k      0  0:01:55  0:01:50  0:00:05 89026\n",
      " 95  319M   95  303M    0     0  2799k      0  0:01:56  0:01:51  0:00:05     0\n",
      " 95  319M   95  303M    0     0  2774k      0  0:01:57  0:01:52  0:00:05     0\n",
      " 95  319M   95  303M    0     0  2749k      0  0:01:58  0:01:53  0:00:05     0\n",
      " 95  319M   95  303M    0     0  2725k      0  0:01:59  0:01:54  0:00:05     0\n",
      " 95  319M   95  303M    0     0  2705k      0  0:02:00  0:01:54  0:00:06  3382\n",
      " 96  319M   96  307M    0     0  2716k      0  0:02:00  0:01:55  0:00:05  815k\n",
      " 97  319M   97  310M    0     0  2716k      0  0:02:00  0:01:56  0:00:04 1365k\n",
      " 98  319M   98  313M    0     0  2722k      0  0:02:00  0:01:57  0:00:03 2097k\n",
      " 99  319M   99  316M    0     0  2728k      0  0:01:59  0:01:58  0:00:01 2791k\n",
      "100  319M  100  319M    0     0  2731k      0  0:01:59  0:01:59 --:--:-- 3337k\n"
     ]
    }
   ],
   "source": [
    "! bash ./models.sh {configs['model']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer artifact obtained from path c:\\Users\\vaasawa\\Documents\\GitHub\\Azure-Sentinel-Notebooks\\mitre-technique-inference\\artifacts\\distilgpt2-512\\tokenizer\n",
      "Labels artifact obtained from path c:\\Users\\vaasawa\\Documents\\GitHub\\Azure-Sentinel-Notebooks\\mitre-technique-inference\\artifacts\\distilgpt2-512\\labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact obtained from path c:\\Users\\vaasawa\\Documents\\GitHub\\Azure-Sentinel-Notebooks\\mitre-technique-inference\\artifacts\\distilgpt2-512\\model_state_dicts\n",
      "Model on device 'cpu'\n"
     ]
    }
   ],
   "source": [
    "assets = storage_utils.AssetStorage(\n",
    "    configs['model']\n",
    ")\n",
    "\n",
    "inference_model = inference_utils.InferenceClassificationPipeline(\n",
    "    model = assets.model,\n",
    "    tokenizer = assets.tokenizer,\n",
    "    device = assets.device.type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process TI Data\n",
    "\n",
    "- Extract IoCs from the raw Threat Intel reports using the ```iocextract``` package, and ```msticpy```'s IoC Extractor.\n",
    "- Process the raw Threat Intel reports using the NLTK package, while assigning special tokens to IoCs detected in the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_object = process_utils.ProcessData(\n",
    "    configs = configs\n",
    ")\n",
    "\n",
    "processed_data_object.go()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "- MITRE ATT&CK is a knowledge base of adversary tactics and techniques based on real-world attacks on a customer's workspace. The knowledge base is publicly available for use by the community, and is used to develop specific threat models and methodologies across all sectors.\n",
    "- The MITRE Enterprise ATT&CK Matrix represents how an adversary achieves its tactical goal, by performing a certain action. A chain of actions represent the sequence of events that the actor uses to carry out an attack. More information about the kinds of tactics and techniques used by threat actors can be found [here](https://attack.mitre.org/techniques/enterprise/).\n",
    "- The model has been trained on publicly available threat intel data that has enterprise tactics assigned to the entries by security experts. We have scraped data from TRAM, Sentinel Hunting and Detection Queries, Sigma, CTID, and MITRE Repositories to create our training dataset, comprising of 13k entries. The model has been trained on all 191 MITRE Enterprise techniques, but the number of entries per technique used for training varies.\n",
    "- The trained model uses the processed threat intel data as input, and outputs the MITRE Enterprise Technique inferred from the processed text description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = inference_model.go(processed_data_object.processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Partition explainer: 2it [00:31, 31.20s/it]               \n",
      "Partition explainer: 2it [00:17, 17.31s/it]               \n",
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "inference_df = inference_utils.format_predictions(\n",
    "    configs = configs,\n",
    "    processed_data_object = processed_data_object,\n",
    "    labels = assets.labels,\n",
    "    outputs = outputs,\n",
    "    classifier = inference_model.classifier_max_scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DF: (3, 11)\n",
      "Sample Result: \n",
      "Preview: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threat_intel</th>\n",
       "      <th>processed_threat_intel</th>\n",
       "      <th>flag_chunk</th>\n",
       "      <th>num_chunks</th>\n",
       "      <th>flag_iocs</th>\n",
       "      <th>iocs</th>\n",
       "      <th>output</th>\n",
       "      <th>model</th>\n",
       "      <th>flag_explain</th>\n",
       "      <th>shap_base</th>\n",
       "      <th>shap_contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like many threat groups, TG-3390 conducts stra...</td>\n",
       "      <td>like many threat group , alphanumeric_token co...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>{'IP': [], 'EMAIL': [], 'URL': [], 'YARA': [],...</td>\n",
       "      <td>{'label': 'LABEL_78', 'score': 0.2774803936481...</td>\n",
       "      <td>distilgpt2-512</td>\n",
       "      <td>True</td>\n",
       "      <td>{'values': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>{'positive': {}, 'neutral': {'like': 0.0, 'man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        threat_intel  \\\n",
       "0  Like many threat groups, TG-3390 conducts stra...   \n",
       "\n",
       "                              processed_threat_intel  flag_chunk num_chunks  \\\n",
       "0  like many threat group , alphanumeric_token co...       False       None   \n",
       "\n",
       "   flag_iocs                                               iocs  \\\n",
       "0       True  {'IP': [], 'EMAIL': [], 'URL': [], 'YARA': [],...   \n",
       "\n",
       "                                              output           model  \\\n",
       "0  {'label': 'LABEL_78', 'score': 0.2774803936481...  distilgpt2-512   \n",
       "\n",
       "   flag_explain                                          shap_base  \\\n",
       "0          True  {'values': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                   shap_contribution  \n",
       "0  {'positive': {}, 'neutral': {'like': 0.0, 'man...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Shape of Inference DF: {inference_df.shape}')\n",
    "       \n",
    "print('Sample Result: ')\n",
    "if inference_df.empty:\n",
    "    print('Empty Dataframe.')\n",
    "else:\n",
    "    print('Preview: ')\n",
    "    display(inference_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability - Visualisation\n",
    "\n",
    "- We use SHAP (Shapley Additive Explanations, Lundberg and Lee 2016) values to determine which words in our input data contributed to the corresponding MITRE Enterprise Technique prediction.\n",
    "- Based on whether the user configured the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set row index to any specific index of a row in the inference_df that you would like to examine further\n",
    "row_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Dataframe row index: 0 \n",
      "\n",
      "Threat Intel Data: \n",
      "\n",
      "Like many threat groups, TG-3390 conducts strategic web compromises (SWCs), also known as watering hole attacks, on websites associated with the target organization's vertical or demographic to increase the likelihood of finding victims with relevant information.\n",
      "\n",
      "Processed Data: \n",
      "like many threat group , alphanumeric_token conduct strategic web compromise ( swcs ) , also known watering hole attack , website associated target organization 's vertical demographic increase likelihood finding victim relevant information .\n",
      "\n",
      "Predicted Label: \n",
      "{'label': 'LABEL_78', 'score': 0.2774803936481476, 'technique': 'T1190'}\n",
      "\n",
      "Insufficient shap data for explainability.\n"
     ]
    }
   ],
   "source": [
    "inference_results = inference_utils.process_shap_explainability_for_row(\n",
    "    inference_df, row_index\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9379f31aa79e9f3733e42c9f886d154b4224f9219b4198d46949455f975e1f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
